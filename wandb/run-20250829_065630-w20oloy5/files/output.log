                                                                                                                                                                                 
{'loss': 3.3547, 'grad_norm': 9.625, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 3.5274, 'grad_norm': 9.5625, 'learning_rate': 1.282051282051282e-07, 'epoch': 0.0}
{'loss': 3.4566, 'grad_norm': 11.0625, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
{'loss': 3.4555, 'grad_norm': 10.5, 'learning_rate': 3.846153846153847e-07, 'epoch': 0.0}
{'loss': 3.2545, 'grad_norm': 8.8125, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
{'loss': 3.4332, 'grad_norm': 10.8125, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.0}
{'loss': 3.472, 'grad_norm': 10.1875, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
{'loss': 3.4308, 'grad_norm': 10.5625, 'learning_rate': 8.974358974358975e-07, 'epoch': 0.01}
{'loss': 3.3561, 'grad_norm': 10.1875, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.01}
{'loss': 3.4427, 'grad_norm': 10.6875, 'learning_rate': 1.153846153846154e-06, 'epoch': 0.01}
{'loss': 3.5281, 'grad_norm': 9.4375, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.01}
{'loss': 3.3046, 'grad_norm': 9.1875, 'learning_rate': 1.4102564102564104e-06, 'epoch': 0.01}
{'loss': 3.4422, 'grad_norm': 11.0625, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.01}
{'loss': 3.4859, 'grad_norm': 10.8125, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.01}
{'loss': 3.3885, 'grad_norm': 9.375, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.01}
{'loss': 3.5329, 'grad_norm': 9.4375, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.01}
{'loss': 3.5279, 'grad_norm': 9.25, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.01}
{'loss': 3.3059, 'grad_norm': 9.3125, 'learning_rate': 2.1794871794871797e-06, 'epoch': 0.01}
{'loss': 3.443, 'grad_norm': 8.5625, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.01}
{'loss': 3.5082, 'grad_norm': 9.0625, 'learning_rate': 2.435897435897436e-06, 'epoch': 0.01}
{'loss': 3.3914, 'grad_norm': 10.9375, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.01}
{'loss': 3.4905, 'grad_norm': 9.0, 'learning_rate': 2.6923076923076923e-06, 'epoch': 0.01}
{'loss': 3.4456, 'grad_norm': 10.5, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.01}
{'loss': 3.4781, 'grad_norm': 8.9375, 'learning_rate': 2.948717948717949e-06, 'epoch': 0.02}
{'loss': 3.3523, 'grad_norm': 8.4375, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.02}
                                                                                                                                                                                 
{'eval_loss': 3.44199538230896, 'eval_runtime': 5.3638, 'eval_samples_per_second': 186.996, 'eval_steps_per_second': 23.491, 'epoch': 0.02}
{'loss': 3.2871, 'grad_norm': 8.75, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.02}
{'loss': 3.4522, 'grad_norm': 8.125, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.02}
{'loss': 3.437, 'grad_norm': 9.4375, 'learning_rate': 3.4615384615384617e-06, 'epoch': 0.02}
{'loss': 3.4083, 'grad_norm': 9.125, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.02}
{'loss': 3.4403, 'grad_norm': 9.75, 'learning_rate': 3.7179487179487184e-06, 'epoch': 0.02}
{'loss': 3.3746, 'grad_norm': 9.125, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.02}
{'loss': 3.4613, 'grad_norm': 10.9375, 'learning_rate': 3.974358974358974e-06, 'epoch': 0.02}
{'loss': 3.3705, 'grad_norm': 9.3125, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.02}
{'loss': 3.469, 'grad_norm': 9.1875, 'learning_rate': 4.230769230769231e-06, 'epoch': 0.02}
{'loss': 3.4385, 'grad_norm': 9.1875, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.02}
{'loss': 3.5377, 'grad_norm': 10.1875, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.02}
{'loss': 3.5216, 'grad_norm': 9.0, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.02}
{'loss': 3.3027, 'grad_norm': 9.25, 'learning_rate': 4.743589743589744e-06, 'epoch': 0.02}
{'loss': 3.4083, 'grad_norm': 8.375, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.03}
{'loss': 3.446, 'grad_norm': 7.8125, 'learning_rate': 5e-06, 'epoch': 0.03}
{'loss': 3.4592, 'grad_norm': 8.625, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.03}
{'loss': 3.473, 'grad_norm': 9.0625, 'learning_rate': 5.256410256410257e-06, 'epoch': 0.03}
{'loss': 3.3466, 'grad_norm': 8.8125, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.03}
{'loss': 3.3809, 'grad_norm': 7.75, 'learning_rate': 5.512820512820514e-06, 'epoch': 0.03}
{'loss': 3.4073, 'grad_norm': 9.375, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.03}
{'loss': 3.413, 'grad_norm': 9.25, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.03}
{'loss': 3.2243, 'grad_norm': 8.6875, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.03}
{'loss': 3.497, 'grad_norm': 8.8125, 'learning_rate': 6.025641025641026e-06, 'epoch': 0.03}
{'loss': 3.436, 'grad_norm': 9.125, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.03}
{'loss': 3.5367, 'grad_norm': 9.3125, 'learning_rate': 6.282051282051282e-06, 'epoch': 0.03}
{'eval_loss': 3.434748411178589, 'eval_runtime': 5.3849, 'eval_samples_per_second': 186.26, 'eval_steps_per_second': 23.399, 'epoch': 0.03}
{'loss': 3.5095, 'grad_norm': 8.375, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.03}
{'loss': 3.4541, 'grad_norm': 8.0625, 'learning_rate': 6.538461538461539e-06, 'epoch': 0.03}
{'loss': 3.5108, 'grad_norm': 9.0625, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.03}
{'loss': 3.3773, 'grad_norm': 8.0, 'learning_rate': 6.794871794871796e-06, 'epoch': 0.03}
{'loss': 3.4117, 'grad_norm': 8.375, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.04}
{'loss': 3.3812, 'grad_norm': 8.625, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.04}
{'loss': 3.5272, 'grad_norm': 9.125, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.04}
{'loss': 3.4208, 'grad_norm': 8.3125, 'learning_rate': 7.307692307692308e-06, 'epoch': 0.04}
{'loss': 3.37, 'grad_norm': 8.5, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.04}
{'loss': 3.3965, 'grad_norm': 8.25, 'learning_rate': 7.564102564102564e-06, 'epoch': 0.04}
{'loss': 3.3912, 'grad_norm': 7.8125, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.04}
{'loss': 3.412, 'grad_norm': 8.0625, 'learning_rate': 7.820512820512822e-06, 'epoch': 0.04}
{'loss': 3.4869, 'grad_norm': 8.25, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.04}
{'loss': 3.4, 'grad_norm': 8.375, 'learning_rate': 8.076923076923077e-06, 'epoch': 0.04}
{'loss': 3.3713, 'grad_norm': 7.75, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.04}
{'loss': 3.5284, 'grad_norm': 7.875, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.04}
{'loss': 3.3738, 'grad_norm': 7.15625, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.04}
{'loss': 3.3367, 'grad_norm': 6.90625, 'learning_rate': 8.58974358974359e-06, 'epoch': 0.04}
{'loss': 3.5042, 'grad_norm': 7.28125, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.04}
{'loss': 3.4051, 'grad_norm': 7.40625, 'learning_rate': 8.846153846153847e-06, 'epoch': 0.05}
{'loss': 3.2663, 'grad_norm': 7.15625, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.05}
{'loss': 3.4234, 'grad_norm': 6.65625, 'learning_rate': 9.102564102564104e-06, 'epoch': 0.05}
{'loss': 3.4176, 'grad_norm': 6.84375, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.05}
{'loss': 3.485, 'grad_norm': 7.1875, 'learning_rate': 9.358974358974359e-06, 'epoch': 0.05}
{'loss': 3.3712, 'grad_norm': 7.15625, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.05}
{'eval_loss': 3.418649435043335, 'eval_runtime': 5.3948, 'eval_samples_per_second': 185.919, 'eval_steps_per_second': 23.356, 'epoch': 0.05}
{'loss': 3.4652, 'grad_norm': 6.75, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.05}
{'loss': 3.4347, 'grad_norm': 6.96875, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.05}
{'loss': 3.5357, 'grad_norm': 7.21875, 'learning_rate': 9.871794871794872e-06, 'epoch': 0.05}
{'loss': 3.3778, 'grad_norm': 6.40625, 'learning_rate': 1e-05, 'epoch': 0.05}
{'loss': 3.2321, 'grad_norm': 6.375, 'learning_rate': 9.993211133740666e-06, 'epoch': 0.05}
{'loss': 3.4473, 'grad_norm': 6.1875, 'learning_rate': 9.986422267481331e-06, 'epoch': 0.05}
{'loss': 3.4689, 'grad_norm': 5.9375, 'learning_rate': 9.979633401221996e-06, 'epoch': 0.05}
{'loss': 3.3273, 'grad_norm': 6.125, 'learning_rate': 9.972844534962663e-06, 'epoch': 0.05}
{'loss': 3.2092, 'grad_norm': 5.5625, 'learning_rate': 9.966055668703328e-06, 'epoch': 0.05}
{'loss': 3.3646, 'grad_norm': 5.9375, 'learning_rate': 9.959266802443993e-06, 'epoch': 0.05}
{'loss': 3.3247, 'grad_norm': 6.03125, 'learning_rate': 9.952477936184658e-06, 'epoch': 0.06}
{'loss': 3.4529, 'grad_norm': 6.3125, 'learning_rate': 9.945689069925323e-06, 'epoch': 0.06}
{'loss': 3.4519, 'grad_norm': 5.96875, 'learning_rate': 9.938900203665988e-06, 'epoch': 0.06}
{'loss': 3.5199, 'grad_norm': 5.84375, 'learning_rate': 9.932111337406653e-06, 'epoch': 0.06}
{'loss': 3.3723, 'grad_norm': 5.59375, 'learning_rate': 9.92532247114732e-06, 'epoch': 0.06}
{'loss': 3.3986, 'grad_norm': 6.46875, 'learning_rate': 9.918533604887985e-06, 'epoch': 0.06}
    main()
  File "/home/jpaulsen/repos/mimi-smollm/train_qa.py", line 160, in main
    trainer.train()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3845, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/accelerator.py", line 2734, in backward
    loss.backward(**kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
