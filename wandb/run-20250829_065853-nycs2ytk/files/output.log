                                                                                                                                                                                 
{'loss': 3.3547, 'grad_norm': 9.625, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 3.5274, 'grad_norm': 9.5625, 'learning_rate': 6.25e-07, 'epoch': 0.0}
{'loss': 3.4528, 'grad_norm': 10.4375, 'learning_rate': 1.25e-06, 'epoch': 0.0}
{'loss': 3.4562, 'grad_norm': 10.375, 'learning_rate': 1.8750000000000003e-06, 'epoch': 0.0}
{'loss': 3.2552, 'grad_norm': 8.9375, 'learning_rate': 2.5e-06, 'epoch': 0.0}
{'loss': 3.4286, 'grad_norm': 10.25, 'learning_rate': 3.125e-06, 'epoch': 0.0}
{'loss': 3.4683, 'grad_norm': 9.8125, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.0}
{'loss': 3.4318, 'grad_norm': 10.8125, 'learning_rate': 4.3750000000000005e-06, 'epoch': 0.01}
{'loss': 3.3556, 'grad_norm': 9.9375, 'learning_rate': 5e-06, 'epoch': 0.01}
{'loss': 3.4415, 'grad_norm': 9.75, 'learning_rate': 5.625e-06, 'epoch': 0.01}
{'loss': 3.5238, 'grad_norm': 9.4375, 'learning_rate': 6.25e-06, 'epoch': 0.01}
{'loss': 3.2995, 'grad_norm': 8.6875, 'learning_rate': 6.875e-06, 'epoch': 0.01}
{'loss': 3.4389, 'grad_norm': 10.4375, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.01}
{'loss': 3.4777, 'grad_norm': 9.6875, 'learning_rate': 8.125000000000001e-06, 'epoch': 0.01}
{'loss': 3.3839, 'grad_norm': 8.6875, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.01}
{'loss': 3.5257, 'grad_norm': 8.75, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.01}
{'loss': 3.5229, 'grad_norm': 8.5, 'learning_rate': 1e-05, 'epoch': 0.01}
{'loss': 3.2956, 'grad_norm': 8.3125, 'learning_rate': 9.999989528163741e-06, 'epoch': 0.01}
{'loss': 3.4363, 'grad_norm': 8.0625, 'learning_rate': 9.999958112698827e-06, 'epoch': 0.01}
{'loss': 3.501, 'grad_norm': 8.0625, 'learning_rate': 9.99990575373685e-06, 'epoch': 0.01}
{'loss': 3.3761, 'grad_norm': 9.4375, 'learning_rate': 9.999832451497127e-06, 'epoch': 0.01}
{'loss': 3.478, 'grad_norm': 7.8125, 'learning_rate': 9.9997382062867e-06, 'epoch': 0.01}
{'loss': 3.433, 'grad_norm': 9.0625, 'learning_rate': 9.99962301850034e-06, 'epoch': 0.01}
{'loss': 3.4688, 'grad_norm': 7.84375, 'learning_rate': 9.999486888620537e-06, 'epoch': 0.02}
{'loss': 3.3407, 'grad_norm': 7.09375, 'learning_rate': 9.999329817217503e-06, 'epoch': 0.02}
                                                                                                                                                                                 
{'eval_loss': 3.427021026611328, 'eval_runtime': 5.39, 'eval_samples_per_second': 186.086, 'eval_steps_per_second': 23.377, 'epoch': 0.02}
{'loss': 3.2722, 'grad_norm': 7.15625, 'learning_rate': 9.999151804949167e-06, 'epoch': 0.02}
{'loss': 3.4418, 'grad_norm': 6.9375, 'learning_rate': 9.998952852561176e-06, 'epoch': 0.02}
{'loss': 3.4218, 'grad_norm': 7.65625, 'learning_rate': 9.99873296088689e-06, 'epoch': 0.02}
{'loss': 3.3937, 'grad_norm': 7.1875, 'learning_rate': 9.998492130847377e-06, 'epoch': 0.02}
{'loss': 3.4211, 'grad_norm': 7.625, 'learning_rate': 9.998230363451408e-06, 'epoch': 0.02}
{'loss': 3.3577, 'grad_norm': 7.46875, 'learning_rate': 9.997947659795457e-06, 'epoch': 0.02}
{'loss': 3.4357, 'grad_norm': 7.5625, 'learning_rate': 9.997644021063698e-06, 'epoch': 0.02}
{'loss': 3.3537, 'grad_norm': 7.34375, 'learning_rate': 9.99731944852799e-06, 'epoch': 0.02}
{'loss': 3.4484, 'grad_norm': 6.75, 'learning_rate': 9.996973943547881e-06, 'epoch': 0.02}
{'loss': 3.4196, 'grad_norm': 7.1875, 'learning_rate': 9.996607507570602e-06, 'epoch': 0.02}
{'loss': 3.5146, 'grad_norm': 7.25, 'learning_rate': 9.996220142131052e-06, 'epoch': 0.02}
{'loss': 3.5053, 'grad_norm': 7.0625, 'learning_rate': 9.995811848851807e-06, 'epoch': 0.02}
{'loss': 3.279, 'grad_norm': 6.28125, 'learning_rate': 9.995382629443095e-06, 'epoch': 0.02}
{'loss': 3.3899, 'grad_norm': 6.0, 'learning_rate': 9.994932485702806e-06, 'epoch': 0.03}
{'loss': 3.4269, 'grad_norm': 5.875, 'learning_rate': 9.99446141951647e-06, 'epoch': 0.03}
{'loss': 3.4365, 'grad_norm': 6.21875, 'learning_rate': 9.993969432857256e-06, 'epoch': 0.03}
{'loss': 3.4487, 'grad_norm': 6.0, 'learning_rate': 9.99345652778597e-06, 'epoch': 0.03}
{'loss': 3.3219, 'grad_norm': 6.4375, 'learning_rate': 9.992922706451034e-06, 'epoch': 0.03}
{'loss': 3.3596, 'grad_norm': 5.53125, 'learning_rate': 9.992367971088482e-06, 'epoch': 0.03}
{'loss': 3.3811, 'grad_norm': 6.75, 'learning_rate': 9.991792324021955e-06, 'epoch': 0.03}
{'loss': 3.3853, 'grad_norm': 6.09375, 'learning_rate': 9.991195767662685e-06, 'epoch': 0.03}
{'loss': 3.2011, 'grad_norm': 6.28125, 'learning_rate': 9.990578304509488e-06, 'epoch': 0.03}
{'loss': 3.4702, 'grad_norm': 6.03125, 'learning_rate': 9.989939937148754e-06, 'epoch': 0.03}
{'loss': 3.4067, 'grad_norm': 5.8125, 'learning_rate': 9.989280668254433e-06, 'epoch': 0.03}
{'loss': 3.5048, 'grad_norm': 5.875, 'learning_rate': 9.988600500588028e-06, 'epoch': 0.03}
{'eval_loss': 3.4062817096710205, 'eval_runtime': 5.3977, 'eval_samples_per_second': 185.818, 'eval_steps_per_second': 23.343, 'epoch': 0.03}
{'loss': 3.4806, 'grad_norm': 4.5625, 'learning_rate': 9.987899436998582e-06, 'epoch': 0.03}
{'loss': 3.4298, 'grad_norm': 5.3125, 'learning_rate': 9.987177480422663e-06, 'epoch': 0.03}
{'loss': 3.4796, 'grad_norm': 5.3125, 'learning_rate': 9.986434633884356e-06, 'epoch': 0.03}
{'loss': 3.3519, 'grad_norm': 4.9375, 'learning_rate': 9.985670900495247e-06, 'epoch': 0.03}
{'loss': 3.3832, 'grad_norm': 5.3125, 'learning_rate': 9.984886283454412e-06, 'epoch': 0.04}
{'loss': 3.3503, 'grad_norm': 5.1875, 'learning_rate': 9.984080786048406e-06, 'epoch': 0.04}
{'loss': 3.4957, 'grad_norm': 5.46875, 'learning_rate': 9.983254411651242e-06, 'epoch': 0.04}
{'loss': 3.3931, 'grad_norm': 5.375, 'learning_rate': 9.982407163724383e-06, 'epoch': 0.04}
{'loss': 3.3383, 'grad_norm': 5.40625, 'learning_rate': 9.981539045816726e-06, 'epoch': 0.04}
{'loss': 3.3658, 'grad_norm': 5.1875, 'learning_rate': 9.980650061564585e-06, 'epoch': 0.04}
{'loss': 3.3653, 'grad_norm': 5.4375, 'learning_rate': 9.979740214691683e-06, 'epoch': 0.04}
{'loss': 3.3821, 'grad_norm': 5.25, 'learning_rate': 9.978809509009121e-06, 'epoch': 0.04}
{'loss': 3.4588, 'grad_norm': 5.4375, 'learning_rate': 9.977857948415383e-06, 'epoch': 0.04}
{'loss': 3.3624, 'grad_norm': 4.90625, 'learning_rate': 9.9768855368963e-06, 'epoch': 0.04}
{'loss': 3.3404, 'grad_norm': 4.4375, 'learning_rate': 9.97589227852505e-06, 'epoch': 0.04}
{'loss': 3.4973, 'grad_norm': 4.84375, 'learning_rate': 9.974878177462127e-06, 'epoch': 0.04}
{'loss': 3.346, 'grad_norm': 4.6875, 'learning_rate': 9.973843237955328e-06, 'epoch': 0.04}
{'loss': 3.3101, 'grad_norm': 4.59375, 'learning_rate': 9.972787464339741e-06, 'epoch': 0.04}
{'loss': 3.4748, 'grad_norm': 4.625, 'learning_rate': 9.971710861037726e-06, 'epoch': 0.04}
{'loss': 3.374, 'grad_norm': 4.65625, 'learning_rate': 9.970613432558882e-06, 'epoch': 0.05}
{'loss': 3.2394, 'grad_norm': 4.6875, 'learning_rate': 9.96949518350005e-06, 'epoch': 0.05}
{'loss': 3.3955, 'grad_norm': 3.9375, 'learning_rate': 9.968356118545277e-06, 'epoch': 0.05}
{'loss': 3.3886, 'grad_norm': 4.5, 'learning_rate': 9.967196242465804e-06, 'epoch': 0.05}
{'loss': 3.4545, 'grad_norm': 4.59375, 'learning_rate': 9.966015560120042e-06, 'epoch': 0.05}
{'loss': 3.3413, 'grad_norm': 4.8125, 'learning_rate': 9.964814076453558e-06, 'epoch': 0.05}
{'eval_loss': 3.3931148052215576, 'eval_runtime': 5.4116, 'eval_samples_per_second': 185.342, 'eval_steps_per_second': 23.283, 'epoch': 0.05}
{'loss': 3.4397, 'grad_norm': 4.90625, 'learning_rate': 9.963591796499047e-06, 'epoch': 0.05}
{'loss': 3.4066, 'grad_norm': 4.875, 'learning_rate': 9.962348725376318e-06, 'epoch': 0.05}
{'loss': 3.5083, 'grad_norm': 5.6875, 'learning_rate': 9.961084868292261e-06, 'epoch': 0.05}
{'loss': 3.3544, 'grad_norm': 4.96875, 'learning_rate': 9.95980023054084e-06, 'epoch': 0.05}
{'loss': 3.2066, 'grad_norm': 4.875, 'learning_rate': 9.958494817503064e-06, 'epoch': 0.05}
{'loss': 3.4223, 'grad_norm': 5.5625, 'learning_rate': 9.957168634646958e-06, 'epoch': 0.05}
{'loss': 3.4454, 'grad_norm': 4.65625, 'learning_rate': 9.955821687527554e-06, 'epoch': 0.05}
{'loss': 3.304, 'grad_norm': 5.09375, 'learning_rate': 9.95445398178685e-06, 'epoch': 0.05}
{'loss': 3.1869, 'grad_norm': 4.15625, 'learning_rate': 9.953065523153807e-06, 'epoch': 0.05}
{'loss': 3.3413, 'grad_norm': 5.1875, 'learning_rate': 9.951656317444308e-06, 'epoch': 0.05}
{'loss': 3.2989, 'grad_norm': 4.59375, 'learning_rate': 9.95022637056114e-06, 'epoch': 0.06}
{'loss': 3.4289, 'grad_norm': 5.34375, 'learning_rate': 9.948775688493974e-06, 'epoch': 0.06}
{'loss': 3.4263, 'grad_norm': 4.65625, 'learning_rate': 9.947304277319332e-06, 'epoch': 0.06}
{'loss': 3.4974, 'grad_norm': 5.15625, 'learning_rate': 9.94581214320056e-06, 'epoch': 0.06}
{'loss': 3.3514, 'grad_norm': 5.1875, 'learning_rate': 9.944299292387818e-06, 'epoch': 0.06}
{'loss': 3.371, 'grad_norm': 5.25, 'learning_rate': 9.94276573121803e-06, 'epoch': 0.06}
{'loss': 3.4607, 'grad_norm': 5.34375, 'learning_rate': 9.941211466114883e-06, 'epoch': 0.06}
{'loss': 3.3499, 'grad_norm': 4.71875, 'learning_rate': 9.939636503588777e-06, 'epoch': 0.06}
{'loss': 3.3544, 'grad_norm': 4.71875, 'learning_rate': 9.938040850236812e-06, 'epoch': 0.06}
{'loss': 3.3882, 'grad_norm': 5.28125, 'learning_rate': 9.936424512742758e-06, 'epoch': 0.06}
{'loss': 3.3705, 'grad_norm': 4.625, 'learning_rate': 9.934787497877021e-06, 'epoch': 0.06}
{'loss': 3.4311, 'grad_norm': 4.71875, 'learning_rate': 9.933129812496623e-06, 'epoch': 0.06}
{'loss': 3.3182, 'grad_norm': 5.625, 'learning_rate': 9.93145146354517e-06, 'epoch': 0.06}
{'loss': 3.3563, 'grad_norm': 4.21875, 'learning_rate': 9.929752458052817e-06, 'epoch': 0.06}
{'loss': 3.2799, 'grad_norm': 4.875, 'learning_rate': 9.928032803136249e-06, 'epoch': 0.06}
{'eval_loss': 3.3776395320892334, 'eval_runtime': 5.4061, 'eval_samples_per_second': 185.531, 'eval_steps_per_second': 23.307, 'epoch': 0.06}
{'loss': 3.3726, 'grad_norm': 4.1875, 'learning_rate': 9.926292505998643e-06, 'epoch': 0.07}
{'loss': 3.319, 'grad_norm': 4.5625, 'learning_rate': 9.924531573929641e-06, 'epoch': 0.07}
{'loss': 3.2695, 'grad_norm': 4.0625, 'learning_rate': 9.92275001430532e-06, 'epoch': 0.07}
{'loss': 3.3314, 'grad_norm': 4.21875, 'learning_rate': 9.920947834588163e-06, 'epoch': 0.07}
{'loss': 3.3042, 'grad_norm': 4.8125, 'learning_rate': 9.919125042327019e-06, 'epoch': 0.07}
{'loss': 3.4339, 'grad_norm': 4.28125, 'learning_rate': 9.917281645157082e-06, 'epoch': 0.07}
{'loss': 3.4223, 'grad_norm': 5.03125, 'learning_rate': 9.915417650799855e-06, 'epoch': 0.07}
{'loss': 3.4122, 'grad_norm': 4.78125, 'learning_rate': 9.913533067063113e-06, 'epoch': 0.07}
{'loss': 3.3104, 'grad_norm': 5.0, 'learning_rate': 9.911627901840877e-06, 'epoch': 0.07}
{'loss': 3.3747, 'grad_norm': 4.625, 'learning_rate': 9.90970216311338e-06, 'epoch': 0.07}
{'loss': 3.2432, 'grad_norm': 4.09375, 'learning_rate': 9.90775585894703e-06, 'epoch': 0.07}
{'loss': 3.3385, 'grad_norm': 4.3125, 'learning_rate': 9.905788997494377e-06, 'epoch': 0.07}
{'loss': 3.4481, 'grad_norm': 4.71875, 'learning_rate': 9.903801586994084e-06, 'epoch': 0.07}
{'loss': 3.3132, 'grad_norm': 4.4375, 'learning_rate': 9.901793635770882e-06, 'epoch': 0.07}
{'loss': 3.2244, 'grad_norm': 4.15625, 'learning_rate': 9.89976515223555e-06, 'epoch': 0.07}
{'loss': 3.3301, 'grad_norm': 4.625, 'learning_rate': 9.897716144884864e-06, 'epoch': 0.07}
{'loss': 3.5608, 'grad_norm': 5.03125, 'learning_rate': 9.89564662230157e-06, 'epoch': 0.08}
{'loss': 3.2949, 'grad_norm': 4.0625, 'learning_rate': 9.893556593154355e-06, 'epoch': 0.08}
{'loss': 3.4249, 'grad_norm': 4.5, 'learning_rate': 9.891446066197789e-06, 'epoch': 0.08}
{'loss': 3.4557, 'grad_norm': 4.40625, 'learning_rate': 9.889315050272315e-06, 'epoch': 0.08}
{'loss': 3.2314, 'grad_norm': 4.25, 'learning_rate': 9.88716355430419e-06, 'epoch': 0.08}
{'loss': 3.1809, 'grad_norm': 4.1875, 'learning_rate': 9.884991587305459e-06, 'epoch': 0.08}
{'loss': 3.5711, 'grad_norm': 5.1875, 'learning_rate': 9.882799158373916e-06, 'epoch': 0.08}
{'loss': 3.4956, 'grad_norm': 4.375, 'learning_rate': 9.880586276693065e-06, 'epoch': 0.08}
{'loss': 3.2252, 'grad_norm': 4.0625, 'learning_rate': 9.878352951532077e-06, 'epoch': 0.08}
{'eval_loss': 3.363781452178955, 'eval_runtime': 5.4025, 'eval_samples_per_second': 185.656, 'eval_steps_per_second': 23.323, 'epoch': 0.08}
{'loss': 3.2809, 'grad_norm': 3.9375, 'learning_rate': 9.876099192245761e-06, 'epoch': 0.08}
{'loss': 3.2515, 'grad_norm': 4.25, 'learning_rate': 9.873825008274514e-06, 'epoch': 0.08}
{'loss': 3.2946, 'grad_norm': 3.765625, 'learning_rate': 9.87153040914429e-06, 'epoch': 0.08}
{'loss': 3.3427, 'grad_norm': 4.21875, 'learning_rate': 9.869215404466557e-06, 'epoch': 0.08}
{'loss': 3.4524, 'grad_norm': 4.4375, 'learning_rate': 9.86688000393825e-06, 'epoch': 0.08}
{'loss': 3.3809, 'grad_norm': 4.125, 'learning_rate': 9.864524217341748e-06, 'epoch': 0.08}
{'loss': 3.5087, 'grad_norm': 3.9375, 'learning_rate': 9.862148054544812e-06, 'epoch': 0.09}
{'loss': 3.4457, 'grad_norm': 4.34375, 'learning_rate': 9.859751525500558e-06, 'epoch': 0.09}
{'loss': 3.3756, 'grad_norm': 4.03125, 'learning_rate': 9.85733464024741e-06, 'epoch': 0.09}
{'loss': 3.3913, 'grad_norm': 4.65625, 'learning_rate': 9.854897408909055e-06, 'epoch': 0.09}
{'loss': 3.304, 'grad_norm': 3.625, 'learning_rate': 9.852439841694414e-06, 'epoch': 0.09}
{'loss': 3.3973, 'grad_norm': 4.21875, 'learning_rate': 9.849961948897582e-06, 'epoch': 0.09}
{'loss': 3.3281, 'grad_norm': 4.4375, 'learning_rate': 9.847463740897792e-06, 'epoch': 0.09}
{'loss': 3.366, 'grad_norm': 4.0625, 'learning_rate': 9.844945228159374e-06, 'epoch': 0.09}
{'loss': 3.2865, 'grad_norm': 3.875, 'learning_rate': 9.842406421231711e-06, 'epoch': 0.09}
{'loss': 3.2295, 'grad_norm': 3.65625, 'learning_rate': 9.83984733074919e-06, 'epoch': 0.09}
{'loss': 3.3209, 'grad_norm': 3.953125, 'learning_rate': 9.837267967431164e-06, 'epoch': 0.09}
{'loss': 3.2647, 'grad_norm': 3.640625, 'learning_rate': 9.834668342081896e-06, 'epoch': 0.09}
{'loss': 3.4397, 'grad_norm': 4.03125, 'learning_rate': 9.832048465590531e-06, 'epoch': 0.09}
{'loss': 3.3951, 'grad_norm': 3.796875, 'learning_rate': 9.829408348931036e-06, 'epoch': 0.09}
{'loss': 3.2961, 'grad_norm': 3.453125, 'learning_rate': 9.826748003162157e-06, 'epoch': 0.09}
{'loss': 3.3988, 'grad_norm': 4.96875, 'learning_rate': 9.824067439427374e-06, 'epoch': 0.09}
{'loss': 3.3336, 'grad_norm': 3.921875, 'learning_rate': 9.821366668954862e-06, 'epoch': 0.1}
{'loss': 3.4311, 'grad_norm': 3.84375, 'learning_rate': 9.818645703057429e-06, 'epoch': 0.1}
{'loss': 3.3786, 'grad_norm': 3.828125, 'learning_rate': 9.815904553132475e-06, 'epoch': 0.1}
{'eval_loss': 3.3487093448638916, 'eval_runtime': 5.4057, 'eval_samples_per_second': 185.546, 'eval_steps_per_second': 23.309, 'epoch': 0.1}
{'loss': 3.2463, 'grad_norm': 3.359375, 'learning_rate': 9.813143230661954e-06, 'epoch': 0.1}
{'loss': 3.1266, 'grad_norm': 3.765625, 'learning_rate': 9.810361747212313e-06, 'epoch': 0.1}
{'loss': 3.2252, 'grad_norm': 3.125, 'learning_rate': 9.807560114434447e-06, 'epoch': 0.1}
{'loss': 3.3737, 'grad_norm': 3.6875, 'learning_rate': 9.804738344063648e-06, 'epoch': 0.1}
{'loss': 3.3669, 'grad_norm': 3.375, 'learning_rate': 9.801896447919568e-06, 'epoch': 0.1}
{'loss': 3.3297, 'grad_norm': 3.375, 'learning_rate': 9.799034437906152e-06, 'epoch': 0.1}
{'loss': 3.4118, 'grad_norm': 3.640625, 'learning_rate': 9.796152326011604e-06, 'epoch': 0.1}
{'loss': 3.4292, 'grad_norm': 3.421875, 'learning_rate': 9.79325012430832e-06, 'epoch': 0.1}
{'loss': 3.4083, 'grad_norm': 3.640625, 'learning_rate': 9.790327844952857e-06, 'epoch': 0.1}
{'loss': 3.4228, 'grad_norm': 3.96875, 'learning_rate': 9.787385500185867e-06, 'epoch': 0.1}
{'loss': 3.3327, 'grad_norm': 2.921875, 'learning_rate': 9.784423102332046e-06, 'epoch': 0.1}
{'loss': 3.386, 'grad_norm': 3.453125, 'learning_rate': 9.781440663800099e-06, 'epoch': 0.1}
{'loss': 3.2228, 'grad_norm': 3.15625, 'learning_rate': 9.778438197082666e-06, 'epoch': 0.11}
{'loss': 3.3435, 'grad_norm': 3.4375, 'learning_rate': 9.775415714756281e-06, 'epoch': 0.11}
{'loss': 3.2698, 'grad_norm': 3.390625, 'learning_rate': 9.772373229481325e-06, 'epoch': 0.11}
{'loss': 3.4458, 'grad_norm': 4.4375, 'learning_rate': 9.769310754001957e-06, 'epoch': 0.11}
{'loss': 3.3683, 'grad_norm': 3.125, 'learning_rate': 9.766228301146074e-06, 'epoch': 0.11}
{'loss': 3.2428, 'grad_norm': 2.78125, 'learning_rate': 9.763125883825253e-06, 'epoch': 0.11}
{'loss': 3.1674, 'grad_norm': 2.6875, 'learning_rate': 9.7600035150347e-06, 'epoch': 0.11}
{'loss': 3.2487, 'grad_norm': 3.15625, 'learning_rate': 9.756861207853183e-06, 'epoch': 0.11}
{'loss': 3.4434, 'grad_norm': 2.921875, 'learning_rate': 9.753698975442995e-06, 'epoch': 0.11}
{'loss': 3.3797, 'grad_norm': 3.4375, 'learning_rate': 9.75051683104989e-06, 'epoch': 0.11}
{'loss': 3.3611, 'grad_norm': 4.4375, 'learning_rate': 9.747314788003024e-06, 'epoch': 0.11}
{'loss': 3.3131, 'grad_norm': 2.875, 'learning_rate': 9.744092859714904e-06, 'epoch': 0.11}
{'loss': 3.3748, 'grad_norm': 3.78125, 'learning_rate': 9.740851059681336e-06, 'epoch': 0.11}
{'eval_loss': 3.336235523223877, 'eval_runtime': 5.4108, 'eval_samples_per_second': 185.37, 'eval_steps_per_second': 23.287, 'epoch': 0.11}
{'loss': 3.385, 'grad_norm': 2.546875, 'learning_rate': 9.737589401481355e-06, 'epoch': 0.11}
{'loss': 3.3274, 'grad_norm': 2.671875, 'learning_rate': 9.734307898777187e-06, 'epoch': 0.11}
{'loss': 3.2993, 'grad_norm': 2.5625, 'learning_rate': 9.73100656531417e-06, 'epoch': 0.11}
{'loss': 3.2697, 'grad_norm': 3.765625, 'learning_rate': 9.727685414920716e-06, 'epoch': 0.12}
{'loss': 3.4219, 'grad_norm': 4.78125, 'learning_rate': 9.72434446150824e-06, 'epoch': 0.12}
{'loss': 3.4109, 'grad_norm': 2.40625, 'learning_rate': 9.720983719071113e-06, 'epoch': 0.12}
{'loss': 3.4438, 'grad_norm': 2.65625, 'learning_rate': 9.71760320168659e-06, 'epoch': 0.12}
{'loss': 3.2755, 'grad_norm': 2.90625, 'learning_rate': 9.714202923514762e-06, 'epoch': 0.12}
{'loss': 3.3246, 'grad_norm': 2.625, 'learning_rate': 9.71078289879849e-06, 'epoch': 0.12}
{'loss': 3.4448, 'grad_norm': 3.765625, 'learning_rate': 9.707343141863348e-06, 'epoch': 0.12}
{'loss': 3.2429, 'grad_norm': 2.6875, 'learning_rate': 9.703883667117571e-06, 'epoch': 0.12}
{'loss': 3.3322, 'grad_norm': 2.484375, 'learning_rate': 9.700404489051974e-06, 'epoch': 0.12}
{'loss': 3.44, 'grad_norm': 2.59375, 'learning_rate': 9.696905622239912e-06, 'epoch': 0.12}
{'loss': 3.3733, 'grad_norm': 2.46875, 'learning_rate': 9.693387081337212e-06, 'epoch': 0.12}
{'loss': 3.2633, 'grad_norm': 2.3125, 'learning_rate': 9.689848881082103e-06, 'epoch': 0.12}
{'loss': 3.3343, 'grad_norm': 2.65625, 'learning_rate': 9.686291036295168e-06, 'epoch': 0.12}
{'loss': 3.3175, 'grad_norm': 2.15625, 'learning_rate': 9.682713561879275e-06, 'epoch': 0.12}
{'loss': 3.2845, 'grad_norm': 2.125, 'learning_rate': 9.679116472819516e-06, 'epoch': 0.12}
{'loss': 3.318, 'grad_norm': 2.328125, 'learning_rate': 9.67549978418314e-06, 'epoch': 0.13}
{'loss': 3.4758, 'grad_norm': 2.671875, 'learning_rate': 9.671863511119494e-06, 'epoch': 0.13}
{'loss': 3.52, 'grad_norm': 2.296875, 'learning_rate': 9.668207668859966e-06, 'epoch': 0.13}
{'loss': 3.3228, 'grad_norm': 2.8125, 'learning_rate': 9.664532272717902e-06, 'epoch': 0.13}
{'loss': 3.3264, 'grad_norm': 2.484375, 'learning_rate': 9.660837338088565e-06, 'epoch': 0.13}
{'loss': 3.3529, 'grad_norm': 2.453125, 'learning_rate': 9.657122880449052e-06, 'epoch': 0.13}
{'loss': 3.2792, 'grad_norm': 2.125, 'learning_rate': 9.653388915358244e-06, 'epoch': 0.13}
{'eval_loss': 3.3263957500457764, 'eval_runtime': 5.4117, 'eval_samples_per_second': 185.338, 'eval_steps_per_second': 23.283, 'epoch': 0.13}
{'loss': 3.3727, 'grad_norm': 2.265625, 'learning_rate': 9.649635458456726e-06, 'epoch': 0.13}
{'loss': 3.4382, 'grad_norm': 2.40625, 'learning_rate': 9.645862525466734e-06, 'epoch': 0.13}
{'loss': 3.3749, 'grad_norm': 2.390625, 'learning_rate': 9.64207013219208e-06, 'epoch': 0.13}
{'loss': 3.2903, 'grad_norm': 2.234375, 'learning_rate': 9.638258294518098e-06, 'epoch': 0.13}
{'loss': 3.1521, 'grad_norm': 2.1875, 'learning_rate': 9.63442702841156e-06, 'epoch': 0.13}
{'loss': 3.3834, 'grad_norm': 1.984375, 'learning_rate': 9.630576349920622e-06, 'epoch': 0.13}
{'loss': 3.2303, 'grad_norm': 2.171875, 'learning_rate': 9.626706275174754e-06, 'epoch': 0.13}
{'loss': 3.37, 'grad_norm': 2.546875, 'learning_rate': 9.622816820384675e-06, 'epoch': 0.13}
{'loss': 3.297, 'grad_norm': 2.4375, 'learning_rate': 9.618908001842274e-06, 'epoch': 0.13}
{'loss': 3.2453, 'grad_norm': 2.15625, 'learning_rate': 9.614979835920557e-06, 'epoch': 0.14}
{'loss': 3.3086, 'grad_norm': 2.21875, 'learning_rate': 9.611032339073568e-06, 'epoch': 0.14}
{'loss': 3.2496, 'grad_norm': 2.09375, 'learning_rate': 9.607065527836324e-06, 'epoch': 0.14}
{'loss': 3.215, 'grad_norm': 2.015625, 'learning_rate': 9.60307941882474e-06, 'epoch': 0.14}
{'loss': 3.4369, 'grad_norm': 2.046875, 'learning_rate': 9.599074028735572e-06, 'epoch': 0.14}
{'loss': 3.3241, 'grad_norm': 1.9296875, 'learning_rate': 9.595049374346334e-06, 'epoch': 0.14}
{'loss': 3.2822, 'grad_norm': 2.203125, 'learning_rate': 9.591005472515238e-06, 'epoch': 0.14}
{'loss': 3.2847, 'grad_norm': 2.25, 'learning_rate': 9.58694234018111e-06, 'epoch': 0.14}
{'loss': 3.3316, 'grad_norm': 2.078125, 'learning_rate': 9.582859994363336e-06, 'epoch': 0.14}
{'loss': 3.4395, 'grad_norm': 2.265625, 'learning_rate': 9.578758452161778e-06, 'epoch': 0.14}
{'loss': 3.3227, 'grad_norm': 1.9375, 'learning_rate': 9.574637730756707e-06, 'epoch': 0.14}
    main()
  File "/home/jpaulsen/repos/mimi-smollm/train_qa.py", line 160, in main
    trainer.train()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3796, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3884, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py", line 478, in forward
    loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/loss/loss_utils.py", line 67, in ForCausalLMLoss
    loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/loss/loss_utils.py", line 36, in fixed_cross_entropy
    loss = nn.functional.cross_entropy(source, target, ignore_index=ignore_index, reduction=reduction)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/nn/functional.py", line 3494, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.21 GiB. GPU 0 has a total capacity of 23.57 GiB of which 5.59 GiB is free. Including non-PyTorch memory, this process has 17.43 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 2.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
