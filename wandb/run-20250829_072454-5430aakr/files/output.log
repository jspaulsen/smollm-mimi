                                                                                                                                                                                 
{'loss': 3.2757, 'grad_norm': 3.640625, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 3.4738, 'grad_norm': 3.703125, 'learning_rate': 1.875e-06, 'epoch': 0.0}
{'loss': 3.4203, 'grad_norm': 4.21875, 'learning_rate': 3.75e-06, 'epoch': 0.0}
{'loss': 3.3998, 'grad_norm': 4.28125, 'learning_rate': 5.625e-06, 'epoch': 0.0}
{'loss': 3.1851, 'grad_norm': 3.375, 'learning_rate': 7.5e-06, 'epoch': 0.0}
{'loss': 3.3963, 'grad_norm': 4.40625, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.0}
{'loss': 3.4325, 'grad_norm': 4.09375, 'learning_rate': 1.125e-05, 'epoch': 0.0}
{'loss': 3.3754, 'grad_norm': 4.15625, 'learning_rate': 1.3125e-05, 'epoch': 0.01}
{'loss': 3.2939, 'grad_norm': 3.90625, 'learning_rate': 1.5e-05, 'epoch': 0.01}
{'loss': 3.39, 'grad_norm': 4.15625, 'learning_rate': 1.6875e-05, 'epoch': 0.01}
{'loss': 3.4691, 'grad_norm': 3.90625, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.01}
{'loss': 3.2445, 'grad_norm': 3.46875, 'learning_rate': 2.0625e-05, 'epoch': 0.01}
{'loss': 3.3922, 'grad_norm': 3.953125, 'learning_rate': 2.25e-05, 'epoch': 0.01}
{'loss': 3.4345, 'grad_norm': 3.65625, 'learning_rate': 2.4375e-05, 'epoch': 0.01}
{'loss': 3.3153, 'grad_norm': 4.0, 'learning_rate': 2.625e-05, 'epoch': 0.01}
{'loss': 3.4423, 'grad_norm': 3.5, 'learning_rate': 2.8125e-05, 'epoch': 0.01}
{'loss': 3.4378, 'grad_norm': 3.53125, 'learning_rate': 3e-05, 'epoch': 0.01}
{'loss': 3.2228, 'grad_norm': 3.40625, 'learning_rate': 2.9999968584491223e-05, 'epoch': 0.01}
{'loss': 3.3471, 'grad_norm': 3.0625, 'learning_rate': 2.999987433809648e-05, 'epoch': 0.01}
{'loss': 3.3945, 'grad_norm': 3.046875, 'learning_rate': 2.9999717261210548e-05, 'epoch': 0.01}
{'loss': 3.3012, 'grad_norm': 3.5, 'learning_rate': 2.9999497354491377e-05, 'epoch': 0.01}
{'loss': 3.3777, 'grad_norm': 3.578125, 'learning_rate': 2.9999214618860097e-05, 'epoch': 0.01}
{'loss': 3.3605, 'grad_norm': 3.375, 'learning_rate': 2.9998869055501018e-05, 'epoch': 0.01}
{'loss': 3.3431, 'grad_norm': 2.765625, 'learning_rate': 2.9998460665861607e-05, 'epoch': 0.02}
{'loss': 3.227, 'grad_norm': 2.8125, 'learning_rate': 2.9997989451652506e-05, 'epoch': 0.02}
                                                                                                                                                                                 
{'eval_loss': 3.3143091201782227, 'eval_runtime': 5.3478, 'eval_samples_per_second': 187.553, 'eval_steps_per_second': 23.561, 'epoch': 0.02}
{'loss': 3.1799, 'grad_norm': 2.78125, 'learning_rate': 2.9997455414847497e-05, 'epoch': 0.02}
{'loss': 3.2933, 'grad_norm': 3.453125, 'learning_rate': 2.9996858557683527e-05, 'epoch': 0.02}
{'loss': 3.3165, 'grad_norm': 3.3125, 'learning_rate': 2.9996198882660668e-05, 'epoch': 0.02}
{'loss': 3.3121, 'grad_norm': 2.78125, 'learning_rate': 2.999547639254213e-05, 'epoch': 0.02}
{'loss': 3.2835, 'grad_norm': 4.1875, 'learning_rate': 2.9994691090354222e-05, 'epoch': 0.02}
{'loss': 3.2493, 'grad_norm': 4.15625, 'learning_rate': 2.999384297938637e-05, 'epoch': 0.02}
{'loss': 3.3004, 'grad_norm': 4.78125, 'learning_rate': 2.999293206319109e-05, 'epoch': 0.02}
{'loss': 3.1886, 'grad_norm': 4.03125, 'learning_rate': 2.9991958345583966e-05, 'epoch': 0.02}
{'loss': 3.2695, 'grad_norm': 3.265625, 'learning_rate': 2.999092183064364e-05, 'epoch': 0.02}
{'loss': 3.2655, 'grad_norm': 3.40625, 'learning_rate': 2.9989822522711803e-05, 'epoch': 0.02}
{'loss': 3.3546, 'grad_norm': 3.84375, 'learning_rate': 2.9988660426393154e-05, 'epoch': 0.02}
{'loss': 3.2826, 'grad_norm': 4.40625, 'learning_rate': 2.998743554655542e-05, 'epoch': 0.02}
{'loss': 3.1193, 'grad_norm': 3.5, 'learning_rate': 2.9986147888329286e-05, 'epoch': 0.02}
{'loss': 3.209, 'grad_norm': 3.328125, 'learning_rate': 2.9984797457108418e-05, 'epoch': 0.03}
{'loss': 3.2529, 'grad_norm': 2.6875, 'learning_rate': 2.9983384258549405e-05, 'epoch': 0.03}
{'loss': 3.2644, 'grad_norm': 3.140625, 'learning_rate': 2.998190829857177e-05, 'epoch': 0.03}
{'loss': 3.2635, 'grad_norm': 3.25, 'learning_rate': 2.998036958335791e-05, 'epoch': 0.03}
{'loss': 3.1415, 'grad_norm': 2.671875, 'learning_rate': 2.99787681193531e-05, 'epoch': 0.03}
{'loss': 3.1726, 'grad_norm': 2.1875, 'learning_rate': 2.9977103913265445e-05, 'epoch': 0.03}
{'loss': 3.1975, 'grad_norm': 3.125, 'learning_rate': 2.9975376972065868e-05, 'epoch': 0.03}
{'loss': 3.1781, 'grad_norm': 3.0, 'learning_rate': 2.9973587302988054e-05, 'epoch': 0.03}
{'loss': 3.0417, 'grad_norm': 2.578125, 'learning_rate': 2.9971734913528465e-05, 'epoch': 0.03}
{'loss': 3.2532, 'grad_norm': 2.96875, 'learning_rate': 2.9969819811446258e-05, 'epoch': 0.03}
{'loss': 3.1843, 'grad_norm': 2.90625, 'learning_rate': 2.9967842004763296e-05, 'epoch': 0.03}
{'loss': 3.257, 'grad_norm': 3.046875, 'learning_rate': 2.9965801501764083e-05, 'epoch': 0.03}
{'eval_loss': 3.2019386291503906, 'eval_runtime': 5.3787, 'eval_samples_per_second': 186.477, 'eval_steps_per_second': 23.426, 'epoch': 0.03}
{'loss': 3.2299, 'grad_norm': 2.046875, 'learning_rate': 2.9963698310995746e-05, 'epoch': 0.03}
{'loss': 3.2389, 'grad_norm': 2.21875, 'learning_rate': 2.9961532441267986e-05, 'epoch': 0.03}
{'loss': 3.2626, 'grad_norm': 2.3125, 'learning_rate': 2.9959303901653065e-05, 'epoch': 0.03}
{'loss': 3.1413, 'grad_norm': 2.59375, 'learning_rate': 2.995701270148574e-05, 'epoch': 0.03}
{'loss': 3.153, 'grad_norm': 1.9375, 'learning_rate': 2.9954658850363235e-05, 'epoch': 0.04}
{'loss': 3.1644, 'grad_norm': 2.015625, 'learning_rate': 2.9952242358145218e-05, 'epoch': 0.04}
{'loss': 3.257, 'grad_norm': 2.125, 'learning_rate': 2.9949763234953724e-05, 'epoch': 0.04}
{'loss': 3.1972, 'grad_norm': 1.75, 'learning_rate': 2.9947221491173147e-05, 'epoch': 0.04}
{'loss': 3.1292, 'grad_norm': 1.9765625, 'learning_rate': 2.9944617137450175e-05, 'epoch': 0.04}
{'loss': 3.1704, 'grad_norm': 2.046875, 'learning_rate': 2.9941950184693754e-05, 'epoch': 0.04}
{'loss': 3.1599, 'grad_norm': 1.875, 'learning_rate': 2.9939220644075045e-05, 'epoch': 0.04}
{'loss': 3.1506, 'grad_norm': 1.9296875, 'learning_rate': 2.993642852702736e-05, 'epoch': 0.04}
{'loss': 3.2312, 'grad_norm': 2.03125, 'learning_rate': 2.9933573845246145e-05, 'epoch': 0.04}
{'loss': 3.1023, 'grad_norm': 1.8125, 'learning_rate': 2.9930656610688902e-05, 'epoch': 0.04}
{'loss': 3.1606, 'grad_norm': 1.703125, 'learning_rate': 2.992767683557515e-05, 'epoch': 0.04}
{'loss': 3.2658, 'grad_norm': 1.953125, 'learning_rate': 2.992463453238638e-05, 'epoch': 0.04}
{'loss': 3.1224, 'grad_norm': 1.8984375, 'learning_rate': 2.992152971386598e-05, 'epoch': 0.04}
{'loss': 3.1179, 'grad_norm': 2.109375, 'learning_rate': 2.9918362393019223e-05, 'epoch': 0.04}
{'loss': 3.2451, 'grad_norm': 1.8515625, 'learning_rate': 2.9915132583113177e-05, 'epoch': 0.04}
{'loss': 3.1321, 'grad_norm': 1.625, 'learning_rate': 2.9911840297676644e-05, 'epoch': 0.05}
{'loss': 3.0478, 'grad_norm': 1.8515625, 'learning_rate': 2.9908485550500152e-05, 'epoch': 0.05}
{'loss': 3.2096, 'grad_norm': 1.6328125, 'learning_rate': 2.990506835563583e-05, 'epoch': 0.05}
{'loss': 3.1299, 'grad_norm': 1.734375, 'learning_rate': 2.990158872739741e-05, 'epoch': 0.05}
{'loss': 3.1922, 'grad_norm': 1.6015625, 'learning_rate': 2.9898046680360123e-05, 'epoch': 0.05}
{'loss': 3.0982, 'grad_norm': 1.78125, 'learning_rate': 2.9894442229360674e-05, 'epoch': 0.05}
{'eval_loss': 3.151320695877075, 'eval_runtime': 5.4061, 'eval_samples_per_second': 185.532, 'eval_steps_per_second': 23.307, 'epoch': 0.05}
{'loss': 3.2022, 'grad_norm': 1.703125, 'learning_rate': 2.9890775389497144e-05, 'epoch': 0.05}
{'loss': 3.1784, 'grad_norm': 1.7890625, 'learning_rate': 2.988704617612895e-05, 'epoch': 0.05}
{'loss': 3.2728, 'grad_norm': 1.6640625, 'learning_rate': 2.988325460487678e-05, 'epoch': 0.05}
{'loss': 3.1137, 'grad_norm': 1.6015625, 'learning_rate': 2.9879400691622524e-05, 'epoch': 0.05}
{'loss': 2.9546, 'grad_norm': 1.96875, 'learning_rate': 2.987548445250919e-05, 'epoch': 0.05}
{'loss': 3.1513, 'grad_norm': 1.6328125, 'learning_rate': 2.9871505903940873e-05, 'epoch': 0.05}
{'loss': 3.2039, 'grad_norm': 1.640625, 'learning_rate': 2.986746506258266e-05, 'epoch': 0.05}
{'loss': 3.0599, 'grad_norm': 1.515625, 'learning_rate': 2.986336194536055e-05, 'epoch': 0.05}
{'loss': 2.9618, 'grad_norm': 1.4140625, 'learning_rate': 2.985919656946142e-05, 'epoch': 0.05}
{'loss': 3.105, 'grad_norm': 1.6484375, 'learning_rate': 2.985496895233292e-05, 'epoch': 0.05}
{'loss': 3.0619, 'grad_norm': 1.5546875, 'learning_rate': 2.985067911168342e-05, 'epoch': 0.06}
{'loss': 3.1916, 'grad_norm': 1.640625, 'learning_rate': 2.984632706548192e-05, 'epoch': 0.06}
{'loss': 3.1808, 'grad_norm': 1.71875, 'learning_rate': 2.9841912831957993e-05, 'epoch': 0.06}
{'loss': 3.2685, 'grad_norm': 1.46875, 'learning_rate': 2.983743642960168e-05, 'epoch': 0.06}
{'loss': 3.1091, 'grad_norm': 1.59375, 'learning_rate': 2.9832897877163453e-05, 'epoch': 0.06}
{'loss': 3.1564, 'grad_norm': 1.6953125, 'learning_rate': 2.9828297193654092e-05, 'epoch': 0.06}
{'loss': 3.2027, 'grad_norm': 1.5625, 'learning_rate': 2.9823634398344647e-05, 'epoch': 0.06}
{'loss': 3.0907, 'grad_norm': 1.421875, 'learning_rate': 2.9818909510766327e-05, 'epoch': 0.06}
{'loss': 3.1073, 'grad_norm': 1.484375, 'learning_rate': 2.9814122550710434e-05, 'epoch': 0.06}
{'loss': 3.127, 'grad_norm': 1.6875, 'learning_rate': 2.980927353822827e-05, 'epoch': 0.06}
{'loss': 3.0827, 'grad_norm': 1.609375, 'learning_rate': 2.980436249363106e-05, 'epoch': 0.06}
{'loss': 3.1692, 'grad_norm': 1.703125, 'learning_rate': 2.979938943748987e-05, 'epoch': 0.06}
{'loss': 3.0655, 'grad_norm': 1.6484375, 'learning_rate': 2.9794354390635506e-05, 'epoch': 0.06}
{'loss': 3.1138, 'grad_norm': 1.640625, 'learning_rate': 2.978925737415845e-05, 'epoch': 0.06}
{'loss': 3.0297, 'grad_norm': 1.546875, 'learning_rate': 2.9784098409408743e-05, 'epoch': 0.06}
{'eval_loss': 3.1185340881347656, 'eval_runtime': 5.4103, 'eval_samples_per_second': 185.387, 'eval_steps_per_second': 23.289, 'epoch': 0.06}
{'loss': 3.1182, 'grad_norm': 1.4765625, 'learning_rate': 2.9778877517995925e-05, 'epoch': 0.07}
{'loss': 3.0759, 'grad_norm': 1.6953125, 'learning_rate': 2.977359472178892e-05, 'epoch': 0.07}
{'loss': 3.046, 'grad_norm': 1.6171875, 'learning_rate': 2.976825004291596e-05, 'epoch': 0.07}
{'loss': 3.0772, 'grad_norm': 1.671875, 'learning_rate': 2.9762843503764487e-05, 'epoch': 0.07}
{'loss': 3.0418, 'grad_norm': 1.9140625, 'learning_rate': 2.9757375126981056e-05, 'epoch': 0.07}
{'loss': 3.1932, 'grad_norm': 1.6171875, 'learning_rate': 2.9751844935471243e-05, 'epoch': 0.07}
{'loss': 3.1557, 'grad_norm': 2.09375, 'learning_rate': 2.9746252952399562e-05, 'epoch': 0.07}
{'loss': 3.1574, 'grad_norm': 1.65625, 'learning_rate': 2.9740599201189334e-05, 'epoch': 0.07}
{'loss': 3.0527, 'grad_norm': 1.5859375, 'learning_rate': 2.9734883705522628e-05, 'epoch': 0.07}
{'loss': 3.122, 'grad_norm': 1.734375, 'learning_rate': 2.972910648934014e-05, 'epoch': 0.07}
{'loss': 2.9611, 'grad_norm': 1.59375, 'learning_rate': 2.972326757684109e-05, 'epoch': 0.07}
{'loss': 3.0707, 'grad_norm': 1.75, 'learning_rate': 2.9717366992483132e-05, 'epoch': 0.07}
{'loss': 3.1629, 'grad_norm': 1.578125, 'learning_rate': 2.971140476098225e-05, 'epoch': 0.07}
{'loss': 3.0933, 'grad_norm': 1.765625, 'learning_rate': 2.9705380907312644e-05, 'epoch': 0.07}
{'loss': 3.002, 'grad_norm': 1.34375, 'learning_rate': 2.9699295456706648e-05, 'epoch': 0.07}
{'loss': 3.0625, 'grad_norm': 1.53125, 'learning_rate': 2.9693148434654588e-05, 'epoch': 0.07}
{'loss': 3.2611, 'grad_norm': 1.8046875, 'learning_rate': 2.968693986690471e-05, 'epoch': 0.08}
{'loss': 3.0136, 'grad_norm': 1.453125, 'learning_rate': 2.968066977946306e-05, 'epoch': 0.08}
{'loss': 3.1467, 'grad_norm': 1.5703125, 'learning_rate': 2.9674338198593368e-05, 'epoch': 0.08}
{'loss': 3.1937, 'grad_norm': 1.4921875, 'learning_rate': 2.9667945150816944e-05, 'epoch': 0.08}
{'loss': 2.9683, 'grad_norm': 1.4375, 'learning_rate': 2.966149066291257e-05, 'epoch': 0.08}
{'loss': 2.9105, 'grad_norm': 1.5234375, 'learning_rate': 2.9654974761916377e-05, 'epoch': 0.08}
{'loss': 3.2645, 'grad_norm': 1.6484375, 'learning_rate': 2.964839747512175e-05, 'epoch': 0.08}
{'loss': 3.1861, 'grad_norm': 1.6171875, 'learning_rate': 2.9641758830079193e-05, 'epoch': 0.08}
{'loss': 3.0007, 'grad_norm': 1.5625, 'learning_rate': 2.9635058854596232e-05, 'epoch': 0.08}
{'eval_loss': 3.0888867378234863, 'eval_runtime': 5.4328, 'eval_samples_per_second': 184.619, 'eval_steps_per_second': 23.192, 'epoch': 0.08}
{'loss': 3.038, 'grad_norm': 1.375, 'learning_rate': 2.9628297576737284e-05, 'epoch': 0.08}
{'loss': 3.0009, 'grad_norm': 1.5546875, 'learning_rate': 2.9621475024823543e-05, 'epoch': 0.08}
{'loss': 3.0438, 'grad_norm': 1.4296875, 'learning_rate': 2.961459122743287e-05, 'epoch': 0.08}
{'loss': 3.0451, 'grad_norm': 1.6953125, 'learning_rate': 2.9607646213399668e-05, 'epoch': 0.08}
{'loss': 3.155, 'grad_norm': 1.734375, 'learning_rate': 2.960064001181475e-05, 'epoch': 0.08}
{'loss': 3.1113, 'grad_norm': 1.7265625, 'learning_rate': 2.9593572652025245e-05, 'epoch': 0.08}
{'loss': 3.2443, 'grad_norm': 1.53125, 'learning_rate': 2.958644416363443e-05, 'epoch': 0.09}
{'loss': 3.1648, 'grad_norm': 1.5625, 'learning_rate': 2.957925457650167e-05, 'epoch': 0.09}
{'loss': 3.111, 'grad_norm': 1.5, 'learning_rate': 2.9572003920742224e-05, 'epoch': 0.09}
{'loss': 3.0902, 'grad_norm': 1.65625, 'learning_rate': 2.9564692226727165e-05, 'epoch': 0.09}
{'loss': 3.0663, 'grad_norm': 1.3046875, 'learning_rate': 2.9557319525083243e-05, 'epoch': 0.09}
{'loss': 3.1356, 'grad_norm': 1.6875, 'learning_rate': 2.9549885846692744e-05, 'epoch': 0.09}
{'loss': 3.0677, 'grad_norm': 1.6875, 'learning_rate': 2.9542391222693374e-05, 'epoch': 0.09}
{'loss': 3.1036, 'grad_norm': 1.4921875, 'learning_rate': 2.953483568447812e-05, 'epoch': 0.09}
{'loss': 2.9919, 'grad_norm': 1.4140625, 'learning_rate': 2.9527219263695132e-05, 'epoch': 0.09}
{'loss': 2.9959, 'grad_norm': 1.4140625, 'learning_rate': 2.951954199224757e-05, 'epoch': 0.09}
{'loss': 3.0721, 'grad_norm': 1.703125, 'learning_rate': 2.9511803902293488e-05, 'epoch': 0.09}
{'loss': 2.9926, 'grad_norm': 1.40625, 'learning_rate': 2.950400502624569e-05, 'epoch': 0.09}
{'loss': 3.1477, 'grad_norm': 1.6171875, 'learning_rate': 2.949614539677159e-05, 'epoch': 0.09}
{'loss': 3.1146, 'grad_norm': 1.6328125, 'learning_rate': 2.9488225046793104e-05, 'epoch': 0.09}
{'loss': 3.0443, 'grad_norm': 1.46875, 'learning_rate': 2.9480244009486467e-05, 'epoch': 0.09}
{'loss': 3.1205, 'grad_norm': 1.734375, 'learning_rate': 2.947220231828212e-05, 'epoch': 0.09}
{'loss': 3.072, 'grad_norm': 1.453125, 'learning_rate': 2.9464100006864583e-05, 'epoch': 0.1}
{'loss': 3.1391, 'grad_norm': 1.5078125, 'learning_rate': 2.9455937109172282e-05, 'epoch': 0.1}
{'loss': 3.1111, 'grad_norm': 1.546875, 'learning_rate': 2.9447713659397428e-05, 'epoch': 0.1}
{'eval_loss': 3.0682623386383057, 'eval_runtime': 5.4068, 'eval_samples_per_second': 185.508, 'eval_steps_per_second': 23.304, 'epoch': 0.1}
{'loss': 3.0153, 'grad_norm': 1.484375, 'learning_rate': 2.943942969198586e-05, 'epoch': 0.1}
{'loss': 2.8792, 'grad_norm': 1.5625, 'learning_rate': 2.943108524163694e-05, 'epoch': 0.1}
{'loss': 3.0011, 'grad_norm': 1.234375, 'learning_rate': 2.942268034330334e-05, 'epoch': 0.1}
{'loss': 3.1232, 'grad_norm': 1.625, 'learning_rate': 2.9414215032190946e-05, 'epoch': 0.1}
{'loss': 3.1052, 'grad_norm': 1.3046875, 'learning_rate': 2.94056893437587e-05, 'epoch': 0.1}
{'loss': 3.0504, 'grad_norm': 1.5, 'learning_rate': 2.9397103313718457e-05, 'epoch': 0.1}
{'loss': 3.125, 'grad_norm': 1.546875, 'learning_rate': 2.9388456978034807e-05, 'epoch': 0.1}
{'loss': 3.1481, 'grad_norm': 1.5234375, 'learning_rate': 2.9379750372924957e-05, 'epoch': 0.1}
{'loss': 3.1226, 'grad_norm': 1.4921875, 'learning_rate': 2.937098353485857e-05, 'epoch': 0.1}
{'loss': 3.1446, 'grad_norm': 1.4609375, 'learning_rate': 2.9362156500557598e-05, 'epoch': 0.1}
{'loss': 3.0657, 'grad_norm': 1.4375, 'learning_rate': 2.935326930699614e-05, 'epoch': 0.1}
{'loss': 3.1043, 'grad_norm': 1.3984375, 'learning_rate': 2.9344321991400294e-05, 'epoch': 0.1}
{'loss': 2.9376, 'grad_norm': 1.3984375, 'learning_rate': 2.9335314591247996e-05, 'epoch': 0.11}
{'loss': 3.0569, 'grad_norm': 1.484375, 'learning_rate': 2.9326247144268846e-05, 'epoch': 0.11}
{'loss': 2.9928, 'grad_norm': 1.6015625, 'learning_rate': 2.931711968844397e-05, 'epoch': 0.11}
{'loss': 3.1816, 'grad_norm': 1.453125, 'learning_rate': 2.930793226200587e-05, 'epoch': 0.11}
{'loss': 3.0381, 'grad_norm': 1.546875, 'learning_rate': 2.929868490343822e-05, 'epoch': 0.11}
{'loss': 2.9655, 'grad_norm': 1.3046875, 'learning_rate': 2.928937765147576e-05, 'epoch': 0.11}
{'loss': 2.9336, 'grad_norm': 1.375, 'learning_rate': 2.9280010545104097e-05, 'epoch': 0.11}
{'loss': 3.0035, 'grad_norm': 1.3671875, 'learning_rate': 2.9270583623559544e-05, 'epoch': 0.11}
{'loss': 3.1342, 'grad_norm': 1.6015625, 'learning_rate': 2.9261096926328986e-05, 'epoch': 0.11}
{'loss': 3.0987, 'grad_norm': 1.5234375, 'learning_rate': 2.925155049314967e-05, 'epoch': 0.11}
{'loss': 3.0965, 'grad_norm': 1.515625, 'learning_rate': 2.924194436400907e-05, 'epoch': 0.11}
{'loss': 3.0229, 'grad_norm': 1.5078125, 'learning_rate': 2.923227857914471e-05, 'epoch': 0.11}
{'loss': 3.1032, 'grad_norm': 3.46875, 'learning_rate': 2.9222553179044003e-05, 'epoch': 0.11}
{'eval_loss': 3.049778938293457, 'eval_runtime': 5.454, 'eval_samples_per_second': 183.903, 'eval_steps_per_second': 23.102, 'epoch': 0.11}
{'loss': 3.0894, 'grad_norm': 1.5234375, 'learning_rate': 2.9212768204444065e-05, 'epoch': 0.11}
{'loss': 3.0433, 'grad_norm': 1.734375, 'learning_rate': 2.9202923696331557e-05, 'epoch': 0.11}
{'loss': 3.0108, 'grad_norm': 1.5390625, 'learning_rate': 2.9193019695942505e-05, 'epoch': 0.11}
{'loss': 2.9763, 'grad_norm': 1.5859375, 'learning_rate': 2.9183056244762145e-05, 'epoch': 0.12}
{'loss': 3.1045, 'grad_norm': 1.8203125, 'learning_rate': 2.9173033384524718e-05, 'epoch': 0.12}
{'loss': 3.1103, 'grad_norm': 1.5, 'learning_rate': 2.9162951157213338e-05, 'epoch': 0.12}
{'loss': 3.138, 'grad_norm': 1.5234375, 'learning_rate': 2.9152809605059766e-05, 'epoch': 0.12}
{'loss': 2.9816, 'grad_norm': 1.484375, 'learning_rate': 2.9142608770544283e-05, 'epoch': 0.12}
{'loss': 3.0081, 'grad_norm': 1.4609375, 'learning_rate': 2.9132348696395463e-05, 'epoch': 0.12}
{'loss': 3.1108, 'grad_norm': 1.609375, 'learning_rate': 2.9122029425590047e-05, 'epoch': 0.12}
{'loss': 2.983, 'grad_norm': 1.4296875, 'learning_rate': 2.9111651001352712e-05, 'epoch': 0.12}
{'loss': 3.03, 'grad_norm': 1.5703125, 'learning_rate': 2.9101213467155917e-05, 'epoch': 0.12}
{'loss': 3.1263, 'grad_norm': 1.765625, 'learning_rate': 2.9090716866719737e-05, 'epoch': 0.12}
{'loss': 3.1137, 'grad_norm': 1.578125, 'learning_rate': 2.9080161244011632e-05, 'epoch': 0.12}
{'loss': 2.9675, 'grad_norm': 2.21875, 'learning_rate': 2.9069546643246306e-05, 'epoch': 0.12}
{'loss': 3.0229, 'grad_norm': 1.4375, 'learning_rate': 2.9058873108885503e-05, 'epoch': 0.12}
{'loss': 3.0632, 'grad_norm': 1.21875, 'learning_rate': 2.9048140685637826e-05, 'epoch': 0.12}
{'loss': 3.0048, 'grad_norm': 1.3515625, 'learning_rate': 2.9037349418458546e-05, 'epoch': 0.12}
{'loss': 3.0493, 'grad_norm': 1.453125, 'learning_rate': 2.902649935254942e-05, 'epoch': 0.13}
{'loss': 3.1421, 'grad_norm': 1.6875, 'learning_rate': 2.9015590533358483e-05, 'epoch': 0.13}
{'loss': 3.2202, 'grad_norm': 5.0, 'learning_rate': 2.9004623006579897e-05, 'epoch': 0.13}
{'loss': 3.057, 'grad_norm': 1.6875, 'learning_rate': 2.8993596818153703e-05, 'epoch': 0.13}
{'loss': 3.0361, 'grad_norm': 1.9609375, 'learning_rate': 2.898251201426569e-05, 'epoch': 0.13}
{'loss': 3.0711, 'grad_norm': 1.4296875, 'learning_rate': 2.8971368641347155e-05, 'epoch': 0.13}
{'loss': 2.9946, 'grad_norm': 1.640625, 'learning_rate': 2.896016674607473e-05, 'epoch': 0.13}
{'eval_loss': 3.030757427215576, 'eval_runtime': 5.4241, 'eval_samples_per_second': 184.916, 'eval_steps_per_second': 23.23, 'epoch': 0.13}
{'loss': 3.0524, 'grad_norm': 1.5390625, 'learning_rate': 2.8948906375370175e-05, 'epoch': 0.13}
{'loss': 3.1417, 'grad_norm': 1.765625, 'learning_rate': 2.8937587576400198e-05, 'epoch': 0.13}
{'loss': 3.0549, 'grad_norm': 1.9140625, 'learning_rate': 2.892621039657624e-05, 'epoch': 0.13}
{'loss': 3.0312, 'grad_norm': 1.46875, 'learning_rate': 2.8914774883554293e-05, 'epoch': 0.13}
{'loss': 2.8866, 'grad_norm': 1.6640625, 'learning_rate': 2.8903281085234675e-05, 'epoch': 0.13}
{'loss': 3.1053, 'grad_norm': 1.5078125, 'learning_rate': 2.8891729049761863e-05, 'epoch': 0.13}
{'loss': 2.9219, 'grad_norm': 1.390625, 'learning_rate': 2.888011882552426e-05, 'epoch': 0.13}
{'loss': 3.0305, 'grad_norm': 1.6171875, 'learning_rate': 2.8868450461154023e-05, 'epoch': 0.13}
{'loss': 3.0059, 'grad_norm': 2.046875, 'learning_rate': 2.8856724005526822e-05, 'epoch': 0.13}
{'loss': 2.9561, 'grad_norm': 1.3515625, 'learning_rate': 2.8844939507761668e-05, 'epoch': 0.14}
{'loss': 3.014, 'grad_norm': 1.4453125, 'learning_rate': 2.8833097017220704e-05, 'epoch': 0.14}
{'loss': 2.9669, 'grad_norm': 1.375, 'learning_rate': 2.882119658350897e-05, 'epoch': 0.14}
{'loss': 2.9138, 'grad_norm': 1.828125, 'learning_rate': 2.880923825647422e-05, 'epoch': 0.14}
{'loss': 3.1454, 'grad_norm': 1.9296875, 'learning_rate': 2.8797222086206713e-05, 'epoch': 0.14}
{'loss': 3.0071, 'grad_norm': 1.6953125, 'learning_rate': 2.8785148123039e-05, 'epoch': 0.14}
{'loss': 3.0057, 'grad_norm': 1.515625, 'learning_rate': 2.8773016417545712e-05, 'epoch': 0.14}
{'loss': 2.9642, 'grad_norm': 1.6640625, 'learning_rate': 2.876082702054333e-05, 'epoch': 0.14}
{'loss': 3.039, 'grad_norm': 2.03125, 'learning_rate': 2.8748579983090007e-05, 'epoch': 0.14}
{'loss': 3.1537, 'grad_norm': 1.484375, 'learning_rate': 2.873627535648533e-05, 'epoch': 0.14}
{'loss': 3.0255, 'grad_norm': 1.4921875, 'learning_rate': 2.872391319227012e-05, 'epoch': 0.14}
    main()
  File "/home/jpaulsen/repos/mimi-smollm/train_qa.py", line 171, in main
    trainer.train()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3796, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3884, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py", line 478, in forward
    loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/loss/loss_utils.py", line 67, in ForCausalLMLoss
    loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/loss/loss_utils.py", line 36, in fixed_cross_entropy
    loss = nn.functional.cross_entropy(source, target, ignore_index=ignore_index, reduction=reduction)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/nn/functional.py", line 3494, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.21 GiB. GPU 0 has a total capacity of 23.57 GiB of which 5.59 GiB is free. Including non-PyTorch memory, this process has 17.43 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 2.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
