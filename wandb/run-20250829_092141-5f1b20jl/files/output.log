  0%|                                                                                                                                                                                                                                                                                                                            | 10/30999 [00:56<47:23:13,  5.50s/it]Traceback (most recent call last):
{'loss': 18.2333, 'grad_norm': 178.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 18.1891, 'grad_norm': 166.0, 'learning_rate': 1.9354838709677416e-06, 'epoch': 0.0}
{'loss': 18.2162, 'grad_norm': 173.0, 'learning_rate': 3.870967741935483e-06, 'epoch': 0.0}
{'loss': 18.0768, 'grad_norm': 163.0, 'learning_rate': 5.8064516129032256e-06, 'epoch': 0.0}
{'loss': 18.131, 'grad_norm': 167.0, 'learning_rate': 7.741935483870966e-06, 'epoch': 0.0}
{'loss': 18.0802, 'grad_norm': 167.0, 'learning_rate': 9.677419354838709e-06, 'epoch': 0.0}
{'loss': 18.0721, 'grad_norm': 171.0, 'learning_rate': 1.1612903225806451e-05, 'epoch': 0.0}
{'loss': 17.9687, 'grad_norm': 166.0, 'learning_rate': 1.3548387096774192e-05, 'epoch': 0.0}
{'loss': 17.8882, 'grad_norm': 162.0, 'learning_rate': 1.5483870967741933e-05, 'epoch': 0.0}
{'loss': 17.7109, 'grad_norm': 161.0, 'learning_rate': 1.7419354838709675e-05, 'epoch': 0.0}
  File "/home/jpaulsen/repos/mimi-smollm/train_emilia.py", line 203, in <module>
    main()
  File "/home/jpaulsen/repos/mimi-smollm/train_emilia.py", line 198, in main
    trainer.train()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3845, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/accelerator.py", line 2734, in backward
    loss.backward(**kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7d2b12a1db20>
Traceback (most recent call last):
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/usr/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
