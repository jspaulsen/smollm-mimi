  0%|                                                                                                                                                                                                                                                                                                                             | 7/30999 [00:37<44:43:35,  5.20s/it]Traceback (most recent call last):
{'loss': 16.8943, 'grad_norm': 145.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 16.7959, 'grad_norm': 134.0, 'learning_rate': 1.9354838709677416e-06, 'epoch': 0.0}
{'loss': 16.8457, 'grad_norm': 124.0, 'learning_rate': 3.870967741935483e-06, 'epoch': 0.0}
{'loss': 16.8447, 'grad_norm': 136.0, 'learning_rate': 5.8064516129032256e-06, 'epoch': 0.0}
{'loss': 16.7439, 'grad_norm': 124.5, 'learning_rate': 7.741935483870966e-06, 'epoch': 0.0}
{'loss': 16.728, 'grad_norm': 137.0, 'learning_rate': 9.677419354838709e-06, 'epoch': 0.0}
{'loss': 16.7015, 'grad_norm': 135.0, 'learning_rate': 1.1612903225806451e-05, 'epoch': 0.0}
  File "/home/jpaulsen/repos/mimi-smollm/train_emilia.py", line 203, in <module>
    if __name__ == "__main__":
        ^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/train_emilia.py", line 198, in main
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3845, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/accelerator.py", line 2734, in backward
    loss.backward(**kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7e1315cc23e0>
Traceback (most recent call last):
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/usr/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
