Memory footprint: 287.91 MB
  0%|                                                                                                                                                              | 8/61073 [00:22<45:08:14,  2.66s/it]Traceback (most recent call last):
{'loss': 18.2991, 'grad_norm': 177.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 18.0659, 'grad_norm': 171.0, 'learning_rate': 9.823182711198428e-08, 'epoch': 0.0}
{'loss': 18.1635, 'grad_norm': 169.0, 'learning_rate': 1.9646365422396855e-07, 'epoch': 0.0}
{'loss': 18.1601, 'grad_norm': 174.0, 'learning_rate': 2.946954813359528e-07, 'epoch': 0.0}
{'loss': 18.142, 'grad_norm': 176.0, 'learning_rate': 3.929273084479371e-07, 'epoch': 0.0}
{'loss': 18.2088, 'grad_norm': 166.0, 'learning_rate': 4.911591355599213e-07, 'epoch': 0.0}
{'loss': 18.1867, 'grad_norm': 171.0, 'learning_rate': 5.893909626719056e-07, 'epoch': 0.0}
{'loss': 18.1093, 'grad_norm': 165.0, 'learning_rate': 6.8762278978389e-07, 'epoch': 0.0}
  File "/home/jpaulsen/repos/mimi-smollm/train_emilia.py", line 205, in <module>
    main()
  File "/home/jpaulsen/repos/mimi-smollm/train_emilia.py", line 200, in main
    trainer.train()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 3845, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/accelerate/accelerator.py", line 2734, in backward
    loss.backward(**kwargs)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x79ec3d479a80>
Traceback (most recent call last):
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/jpaulsen/repos/mimi-smollm/.venv/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/usr/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
